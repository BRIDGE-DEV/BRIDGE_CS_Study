### 서론: 멀티프로세서의 등장

과거 단일 CPU의 성능은 매년 거의 두 배씩 향상되었지만, 2000년대 초반 이후 발열 문제 등으로 인해 성능 개선이 한계에 부딪혔다. 이에 대한 해결책으로 단일 칩에 여러 개의 CPU 코어를 내장하는 멀티코어(multicore) 프로세서가 등장하여 대중화되었다. 이로 인해 멀티프로세서 시스템은 고사양 컴퓨터뿐만 아니라 데스크톱, 노트북, 모바일 기기에서도 일반적이 되었다.

여기서 운영체제는 새로운 문제를 직면하였다. 가장 핵심적인 질문은 "여러 개의 CPU에 작업을 어떻게 효과적으로 스케줄할 것인가?" 이다. 기존의 응용 프로그램들은 대부분 단일 CPU만 사용하도록 설계되었기 때문에, 여러 CPU의 이점을 활용하려면 쓰레드(thread)를 사용하여 병렬로 실행되도록 다시 작성해야 한다. 이에 따라 운영체제 역시 여러 CPU를 효율적으로 관리하기 위한 멀티프로세서 스케줄링 기법을 필요로 하게 되었다.

---

### 멀티프로세서 스케줄링의 배경 및 주요 문제

### 1. 멀티프로세서 구조와 캐시

멀티프로세서 스케줄링을 이해하기 위해서는 하드웨어 구조, 특히 캐시 메모리의 작동 방식을 알아야 한다.

- **캐시(Cache)**: 메인 메모리보다 훨씬 빠르지만 용량이 작은 메모리로, 자주 사용되는 데이터의 복사본을 저장하여 프로그램 실행 속도를 높인다. 시스템은 캐시를 통해 크고 느린 메인 메모리가 마치 빠른 메모리처럼 작동하게 만든다.
- **지역성(Locality)**: 캐시가 효과적으로 작동하는 원리로, 두 가지 종류가 있다.
    - **시간 지역성 (Temporal Locality)**: 한 번 접근된 데이터는 가까운 미래에 다시 접근될 확률이 높다. 예를 들어, 루프 안에서 반복적으로 사용되는 변수를 생각할 수 있다.
    - **공간 지역성 (Spatial Locality)**: 특정 주소의 데이터에 접근하면 그 주변 주소의 데이터도 곧 접근될 확률이 높다. 배열을 순차적으로 접근하는 경우가 이에 해당한다.

### 2. 캐시 일관성 (Cache Coherence) 문제

여러 프로세서가 각자의 캐시를 가지고 공유 메인 메모리에 접근할 때 문제가 발생할 수 있다. 예를 들어, CPU 1이 특정 메모리 주소의 값을 변경하고 자신의 캐시에만 갱신했을 때, CPU 2가 동일한 주소를 메인 메모리에서 읽으면 변경되기 전의 옛날 값을 가져오는 문제가 발생한다. 이를 **캐시 일관성 문제**라고 한다.

이 문제의 기본적인 해결책은 하드웨어를 통해 제공됩니다. **버스 스누핑(bus snooping)** 과 같은 기법을 사용하여, 각 캐시는 버스를 지속적으로 감시하며 다른 캐시에서 발생하는 데이터 변경을 파악한다. 데이터 변경이 감지되면 자신의 캐시에 있는 복사본을 무효화(invalidate)하거나 새로운 값으로 갱신(update)하여 일관성을 유지한다.

### 3. 동기화 (Synchronization)

하드웨어가 캐시 일관성을 보장해주더라도, 여러 CPU의 스레드가 공유 데이터 구조에 동시에 접근할 때 발생하는 문제를 막기 위해서는 소프트웨어 수준의 동기화가 필요하다.

예를 들어, 두 개의 스레드가 연결 리스트에서 동시에 노드를 삭제하려고 시도하면, 두 스레드가 동일한 노드를 제거하려고 하거나 데이터 구조가 손상되는 등의 문제가 발생할 수 있다. 이 문제를 해결하기 위해 락(lock)과 같은 동기화 기법을 사용하여 공유 데이터에 대한 접근이 원자적으로(atomically) 이루어지도록 보장해야 한다. 그러나 락을 사용하는 것은 특히 CPU 수가 증가할수록 성능 저하를 유발할 수 있다.

### 4. 캐시 친화성 (Cache Affinity)

프로세스가 특정 CPU에서 실행되면, 관련된 데이터와 상태 정보가 해당 CPU의 캐시에 저장된다. 따라서 다음에 다시 실행될 때, 같은 CPU에서 실행되는 것이 캐시에 저장된 정보를 재활용할 수 있어 성능에 유리하다. 만약 프로세스가 실행될 때마다 다른 CPU로 옮겨 다니면, 매번 캐시를 새로 채워야 하므로 성능이 저하된다. 그러므로 멀티프로세서 스케줄러는 가능한 한 프로세스를 동일한 CPU에서 계속 실행하여 **캐시 친화성**을 유지하도록 노력해야 한다.

---

### 멀티프로세서 스케줄링 방식

### 1. 단일 큐 멀티프로세서 스케줄링 (SQMS)

가장 기본적인 접근 방식은 모든 작업을 단일 큐에 넣고 관리하는 것이다.

- **장점**:
    - **단순함**: 기존의 단일 프로세서 스케줄링 정책을 거의 그대로 사용할 수 있어 구현이 간단하다.
- **단점**:
    - **확장성 부족**: 단일 큐에 여러 CPU가 동시에 접근하는 것을 막기 위해 락을 사용해야 한다. CPU 수가 증가할수록 이 락을 차지하려는 경쟁이 심해져 심각한 성능 저하를 유발한다.
    - **캐시 친화성 문제**: 작업들이 큐에서 선택될 때마다 다른 CPU로 이동할 가능성이 높아 캐시 친화성을 유지하기 어렵다. 이 문제를 완화하기 위해 특정 작업은 특정 CPU에 고정시키고 일부 작업만 이동시키는 정책을 사용할 수 있지만, 이는 구현을 복잡하게 만든다.

### 2. 멀티 큐 멀티프로세서 스케줄링 (MQMS)

SQMS의 단점을 해결하기 위해 각 CPU마다 별도의 독립된 큐를 두는 방식이다.

- **장점**:
    - **확장성**: 각 CPU가 자신의 큐를 독립적으로 관리하므로 중앙 락이 필요 없어 락으로 인한 성능 저하 문제가 없다.
    - **캐시 친화성**: 작업이 특정 큐에 할당되면 해당 CPU에서 계속 실행되므로 캐시 친화성이 자연스럽게 유지된다.
- **단점**:
    - **워크로드 불균형 (Load Imbalance)**: 작업이 큐에 불균등하게 분배될 수 있다. 예를 들어, 한 CPU의 큐는 비어서 CPU가 유휴 상태에 있는 반면, 다른 CPU는 처리할 작업이 많아 과부하가 걸릴 수 있다.
- **해결책: 이주 (Migration)**
    - 워크로드 불균형 문제는 작업을 한 큐에서 다른 큐로 **이주**시켜 해결할 수 있다.
    - **작업 훔치기 (Work Stealing)**: 이주를 구현하는 대표적인 기술로, 작업이 적은 큐(소스 큐)가 작업이 많은 큐(대상 큐)를 주기적으로 확인하여 작업을 "훔쳐"오는 방식이다.
    - **트레이드오프**: 큐를 너무 자주 검사하면 오버헤드가 커져 확장성의 장점이 사라지고, 너무 드물게 검사하면 심각한 불균형을 방치하게 될 수 있다. 따라서 적절한 검사 주기를 찾는 것이 중요하다.

---

### Linux 멀티프로세서 스케줄러

실제 시스템에서는 단일화된 접근 방식 대신 여러 스케줄러가 개발되어 사용되고 있다. Linux에서는 대표적으로 세 가지 스케줄러가 있다.

- **O(1) 스케줄러**: 우선순위 기반의 멀티 큐 스케줄러
- **Completely Fair Scheduler (CFS)**: 비례 배분 방식의 멀티 큐 스케줄러
- **BF Scheduler (BFS)**: 비례 배분 방식이지만 유일하게 단일 큐를 사용하는 스케줄러

이처럼 실제 성공적으로 사용되는 스케줄러 중에는 멀티 큐와 단일 큐 방식이 모두 존재하며, 두 접근법 모두 장단점을 가지고 있다.